{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_13_한종준_Section2.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 모듈 설치"
      ],
      "metadata": {
        "id": "bglz9ReCvSsR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkGXiXXu7pwP"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "id": "OFpj0P3a8UWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade mplfinance"
      ],
      "metadata": {
        "id": "H98z1PfRUp6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/matplotlib/mpl_finance/archive/master.zip"
      ],
      "metadata": {
        "id": "e0mcjanIXE9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels"
      ],
      "metadata": {
        "id": "2bBp5fLsTWjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "z7XcwE3JBT1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "XCclvQ9CvH_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdpbox"
      ],
      "metadata": {
        "id": "FXBS2XtsvKRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 분석 시작"
      ],
      "metadata": {
        "id": "Fud_zEblvYbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "import ta\n",
        "import datetime\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_finance import candlestick_ohlc\n",
        "import statsmodels.api as sm\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_log_error, mean_squared_error,  r2_score, mean_absolute_error\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Dense, SimpleRNN\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBRegressor\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.neural_network import MLPRegressor \n",
        "from sklearn.neighbors import KNeighborsRegressor \n",
        "from sklearn.svm import SVR \n",
        "from sklearn.model_selection import cross_val_score \n",
        "from sklearn.model_selection import cross_val_predict \n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import shap\n",
        "from pdpbox.pdp import pdp_isolate, pdp_plot\n",
        "from pdpbox.pdp import pdp_interact, pdp_interact_plot"
      ],
      "metadata": {
        "id": "V9BEVwU07q3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple = yf.download('AAPL',start = '1989-10-06')"
      ],
      "metadata": {
        "id": "iQ3DmP8Z7_Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple1 = apple.copy()\n",
        "apple1.columns = ['Open', 'High', 'Low', 'Close', 'Adj', 'Vol']\n",
        "\n",
        "apple1"
      ],
      "metadata": {
        "id": "A5CPGpv38Cfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정종가가 아닌 종가에 대한 이동평균선, RSI, 볼린저 상한밴드, 볼리저 하한밴드, MACD 생성\n",
        "\n",
        "ma12 = apple1['Close'].rolling(window = 12).mean()\n",
        "ma26 = apple1['Close'].rolling(window = 26).mean()\n",
        "RSI = ta.momentum.rsi(apple1['Close'])\n",
        "BOL_H = ta.volatility.bollinger_hband(apple1['Close'])\n",
        "BOL_L = ta.volatility.bollinger_lband(apple1['Close'])\n",
        "MACD = ta.trend.macd(apple1['Close'])"
      ],
      "metadata": {
        "id": "5UL5LGsG8EoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RSI, 볼린저 상한밴드, 볼린저 하한밴드, MACD의 항목을 추가 \n",
        "\n",
        "apple2 = pd.concat([apple1, ma12, ma26, RSI, BOL_H, BOL_L, MACD], axis = 1)\n",
        "\n",
        "apple2.columns = ['Open', 'High', 'Low', 'Close', 'Adj', 'Vol', 'MA_12', 'MA_26', 'RSI', 'BOL_H', 'BOL_L', 'MACD']\n",
        "\n",
        "apple2"
      ],
      "metadata": {
        "id": "nSA3pDyT9qC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal = apple2['MACD'].ewm(9).mean()\n",
        "\n",
        "apple3 = pd.concat([apple2, signal], axis = 1)\n",
        "\n",
        "apple3.columns = ['Open', 'High', 'Low', 'Close', 'Adj', 'Vol', 'MA_12', 'MA_26', 'RSI', 'BOL_H', 'BOL_L', 'MACD', 'SIGNAL']\n",
        "\n",
        "apple3"
      ],
      "metadata": {
        "id": "4TmU8RBfu_3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple3.isnull().sum() # 결측치 확인"
      ],
      "metadata": {
        "id": "XRL0ZtKyCVDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 수가 굉장히 미미한 수준이기 때문에 제거함\n",
        "\n",
        "apple3 = apple3.dropna()\n",
        "\n",
        "apple3"
      ],
      "metadata": {
        "id": "XG9qBbdZCgVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple3.dtypes"
      ],
      "metadata": {
        "id": "GyvRaR0grLeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 각 Column 의미\n",
        "\n",
        "1. Date : 날짜\n",
        "\n",
        "2. Open : 장 시작시 애플의 가격\n",
        "\n",
        "3. High : 장 중 애플의 최고 가격\n",
        "\n",
        "4. Low : 장 중 애플의 최저 가격\n",
        "\n",
        "5. Close : 장 마감시 애플의 가격\n",
        "\n",
        "6. Adj : 장 후 애플의 수정 종가\n",
        "\n",
        "7. Vol : 애플 거래량\n",
        "\n",
        "8. MA_12 : 12일 이동평균선\n",
        "\n",
        "9. MA_26 : 26일 이동평균선\n",
        "\n",
        "10. RSI : 상대 강도 지수\n",
        "\n",
        "11. BOL_H : 볼린저 상한밴드\n",
        "\n",
        "12. BOL_L : 볼린저 하한밴드\n",
        "\n",
        "13. MACD : 추세 분석 지표\n",
        "\n",
        "14. SIGNAL : MACD 상대 반응모델 선\n",
        "\n",
        "\n",
        "*   수정 종가 = 분할, 배당, 배분, 신주 발생이 된 경우를 고려해 주식 가격을 조정(adjustment)해둔 가격. 따라서 굉장히 중요함.\n",
        "\n",
        "*   이동평균선 = 일정 기간동안 주가를 산술평균낸 후 값을 연결한 선으로 5일선은 대표적 단기 이동평균선, 60일선은 대표적 장기 이동평균선이다.\n",
        "\n",
        "*   상대 강도 지수 = 과매수 상태인가, 과매도 상태인가를 나타내는 지표.\n",
        "\n",
        "*   볼린저밴드 = 이동평균선을 중심으로 하는 표준편차. 위쪽으로 상한밴드, 아래쪽으로 하한밴드.\n",
        "\n",
        "*   추세 분석 지표 = 단기 이동평균선 - 장기 이동평균선\n",
        "\n"
      ],
      "metadata": {
        "id": "b8qWBRcfERIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 세부 지표 파악\n",
        "\n",
        "apple3.describe()"
      ],
      "metadata": {
        "id": "SyuGTSlcCyKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 타겟 세부 지표 파악\n",
        "\n",
        "target1 = apple3['High']\n",
        "target2 = apple3['Low']\n",
        "\n",
        "target1.describe(), target2.describe()"
      ],
      "metadata": {
        "id": "ZuG_b7leCrKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 column 들의 분포\n",
        "\n",
        "apple3.hist(bins = 20, grid = True, figsize = (16, 12))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mmd1ha5-JUj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피어슨 상관 계수 분석\n",
        "\n",
        "corr = apple3.corr(method = 'pearson')\n",
        "\n",
        "corr"
      ],
      "metadata": {
        "id": "DpQRv-vnJuo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#변수 끼리의 상관관계 분석\n",
        "\n",
        "apple3.corr().loc[apple3.columns, apple3.columns].style.background_gradient().set_precision(2).set_properties(**{'font-size': '11pt'})"
      ],
      "metadata": {
        "id": "2VwGTKfbskeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. APPLE의 지표들에 대한 피어슨 상관 계수를 나타내었을 때, 거래량만 음의 상관관계를 나타내지만 큰 수치가 아닌 상관관계이다\n",
        "\n",
        "2. MACD 역시 큰 상관관계라고는 볼 수 가 없다."
      ],
      "metadata": {
        "id": "zlSA7kYFJ-7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최근 60거래일 거래현황 시각화\n",
        "\n",
        "apple60 = apple3[-120:]"
      ],
      "metadata": {
        "id": "zTpihRxtJ5Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 60 거래일에 관한 거래현황\n",
        "\n",
        "fig = plt.figure(figsize = (16, 10))\n",
        "fig.set_facecolor('lightgrey')\n",
        "gs = gridspec.GridSpec(4, 1, height_ratios=[5, 1, 1, 1])\n",
        "axes = []\n",
        "axes.append(plt.subplot(gs[0]))\n",
        "axes.append(plt.subplot(gs[1], sharex = axes[0]))\n",
        "axes.append(plt.subplot(gs[2], sharex = axes[1]))\n",
        "axes.append(plt.subplot(gs[3], sharex = axes[2]))\n",
        "axes[0].get_xaxis().set_visible(False)\n",
        "\n",
        "x = np.arange(len(apple60.index))\n",
        "ohlc = apple60[['Open', 'High', 'Low', 'Close']].astype(int).values\n",
        "dohlc = np.hstack((np.reshape(x, (-1, 1)), ohlc))\n",
        "\n",
        "candlestick_ohlc(axes[0], dohlc, width = 0.5, colorup = 'r', colordown = 'b')\n",
        "axes[1].bar(x, apple60.Vol, color = 'black', width = 0.6, align = 'center')\n",
        "axes[2].plot(x, apple60.RSI, color = 'red')\n",
        "axes[3].plot(x, apple60.MACD, color = 'green')\n",
        "axes[3].plot(x, apple60.SIGNAL, color = 'red')\n",
        "axes[3].axhline(0, color = 'black')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "5cBWivPXYmxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIF (Variance Infliation Factor)\n",
        "독립변수를 다른 독립변수들로 선형회귀한 성능을 나타낸다\n",
        "\n",
        "의존성이 낮은(분산이 작은) 독립변수를 선택하거나, 의존성이 높은(분산이 높은) 독립변수를 제거하며 사용한다\n",
        "\n",
        "\n",
        "*    variance_inflation_factor(X, i) : Xi를 x나머지로 회귀분석한 후 VIF값을 구한것. 즉 xi의 vif값. 즉 이값이 높을수록 종속성이 높다는 뜻"
      ],
      "metadata": {
        "id": "GrdWyALm5Jgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vif = pd.DataFrame()\n",
        "\n",
        "vif['VIF_Factor'] = [variance_inflation_factor(apple3.values, i) \n",
        "                     for i in range(apple3.shape[1])]\n",
        "vif['Feature'] = apple3.columns\n",
        "vif.sort_values(by = 'VIF_Factor', ascending = True)"
      ],
      "metadata": {
        "id": "knKoFTe24Wrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시계열 데이터이기 때문에 과적합이 발생할 수 있지만 이 flow 를 타고 예측을 한다는 전제하에 그대로 진행을 해보자\n"
      ],
      "metadata": {
        "id": "9mkBkdv-4Gks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 안정성(정상성) 확인\n"
      ],
      "metadata": {
        "id": "VaPzzFKwBdSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시계열이 정상성이있는지 귀무가설로 판단해보자\n",
        "\n",
        "def adf_test(df):\n",
        "  result = adfuller(df.values)\n",
        "  print('ADF Statics: %f' % result[0])\n",
        "  print('P-value: %f' % result[1])\n",
        "  print('Critical Values:')\n",
        "  for key, value in result[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))\n",
        "\n",
        "adf_test(apple3['High'])"
      ],
      "metadata": {
        "id": "cpwzUDEd--UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "p-value가 0.05보다 높기때문에 시계열은 안정적이지 않다는 귀무가설을 기각할 수 없다.\n",
        "\n",
        "시계열이 안정적이지 않다는 것"
      ],
      "metadata": {
        "id": "bJiXtM4YIz-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kpss_test(df):\n",
        "  statistic, p_value, n_lags, critical_values = kpss(df.values)\n",
        "\n",
        "  print(f'KPSS Statics: {statistic}')\n",
        "  print(f'P-value: {p_value}')\n",
        "  print(f'Num-lags: {n_lags}')\n",
        "  print('Critical Values:')\n",
        "  for key, value in critical_values.items():\n",
        "    print(f' {key} : {value}')\n",
        "\n",
        "kpss_test(apple3['High'])"
      ],
      "metadata": {
        "id": "BjGtSz6oF7CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "p-value가 0.05보다 낮기 때문에 시계열은 안정적이라는 귀무가설을 기각한다\n",
        "\n",
        "결국 시계열은 역시 안정적이지 않다는 것이다."
      ],
      "metadata": {
        "id": "xKYWqn_qJJ1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 안정적인 모습의 데이터일까 \n",
        "\n",
        "주가데이터라 그런지 비슷한 형태의 wave를 가지고 일정 주기동안 반복하는 형태인 정상성을 분석한 결과 결국 데이터가 안정적인 모습이 아니라고 판단된다."
      ],
      "metadata": {
        "id": "9RQKZYBcLzop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Test 셋을 나눈다 - 코로나 범유행 기간을 기준으로 한다\n",
        "\n",
        "def datasplit_ts(df, y_colname, X_colname, criteria):\n",
        "    train = df.loc[df.index < criteria,:]\n",
        "    test = df.loc[df.index >= criteria,:]\n",
        "    y_train = train[y_colname]\n",
        "    X_train = train[X_colname]\n",
        "    y_test = test[y_colname]\n",
        "    X_test = test[X_colname]\n",
        "    print('Train_size:', train.shape, 'Test_size:', test.shape)\n",
        "    print('X_train:', X_train.shape, 'y_train:', y_train.shape)\n",
        "    print('X_test:', X_test.shape, 'y_test:', y_test.shape)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "6ALUM1jKslVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target을 High일 때와 Low일 때 둘로 나눈다\n",
        "\n",
        "y_colname1 = ['High']\n",
        "y_colname2 = ['Low']\n",
        "X_remove1 = ['Date', 'Low']\n",
        "X_remove2 = ['Date', 'High']\n",
        "X_colname1 = [x for x in apple3.columns if x not in y_colname1 + X_remove1]\n",
        "X_colname2 = [x for x in apple3.columns if x not in y_colname2 + X_remove2]\n",
        "X_train1, X_test1, y_train1, y_test1 = datasplit_ts(apple3, y_colname1, X_colname1, '2020-01-02')\n",
        "X_train2, X_test2, y_train2, y_test2 = datasplit_ts(apple3, y_colname2, X_colname2, '2020-01-02')"
      ],
      "metadata": {
        "id": "LPc2PQdar5gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling 진행\n",
        "\n",
        "def feature_engineering_scaling(scaler, X_train, X_test):\n",
        "    # scaler파라미터는 아래 4개중 하나를 넣는다\n",
        "    # preprocessing.MinMaxScaler()\n",
        "    # preprocessing.StandardScaler()\n",
        "    # preprocessing.RobustScaler()\n",
        "    # preprocessing.Normalizer()\n",
        "    scaler = scaler\n",
        "    scaler_fit = scaler.fit(X_train)\n",
        "    X_train_scaling = pd.DataFrame(scaler_fit.transform(X_train), \n",
        "                               index=X_train.index, columns=X_train.columns)\n",
        "    X_test_scaling = pd.DataFrame(scaler_fit.transform(X_test), \n",
        "                               index=X_test.index, columns=X_test.columns)\n",
        "    return X_train_scaling, X_test_scaling"
      ],
      "metadata": {
        "id": "oPE2GmGhmo12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sc1, X_test_sc1 = feature_engineering_scaling(preprocessing.MinMaxScaler(), X_train1, X_test1)\n",
        "X_train_sc2, X_test_sc2 = feature_engineering_scaling(preprocessing.MinMaxScaler(), X_train2, X_test2)"
      ],
      "metadata": {
        "id": "IK-tr6wQuyT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict1 = apple3['High'].mean()\n",
        "predict2 = apple3['Low'].mean()\n",
        "\n",
        "predict1, predict2"
      ],
      "metadata": {
        "id": "yL_4pl9_VDF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기준모델에 대한 시각화\n",
        "\n",
        "x1 = apple3.index\n",
        "y1 = apple3['High']\n",
        "\n",
        "errors = predict1 - apple['High']\n",
        "mean_absolute_error = errors.abs().mean()\n",
        "\n",
        "sns.lineplot(x = x1, y = predict1, color = 'red')\n",
        "sns.scatterplot(x = x1, y = y1, color = 'blue');"
      ],
      "metadata": {
        "id": "p41kCl1-XEN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = apple3.index\n",
        "y2 = apple3['Low']\n",
        "\n",
        "errors = predict1 - apple['Low']\n",
        "mean_absolute_error = errors.abs().mean()\n",
        "\n",
        "sns.lineplot(x = x2, y = predict2, color = 'red')\n",
        "sns.scatterplot(x = x2, y = y2, color = 'blue');"
      ],
      "metadata": {
        "id": "b8nRm0hzYfXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델링 시작\n",
        "\n",
        "1. OLS 모델\n",
        "\n",
        "2. Ridge\n",
        "\n",
        "3. RandomForest를 통한 배깅\n",
        "\n",
        "4. LGBM을 통한 부스팅"
      ],
      "metadata": {
        "id": "sUkfriaV-l7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(y_real, y_pred, graph_on = False):\n",
        "    loss_length = len(y_real.values.flatten()) - len(y_pred)\n",
        "    if loss_length != 0:\n",
        "        y_real = y_real[loss_length:]\n",
        "    if graph_on == True:\n",
        "        pd.concat([y_real, pd.DataFrame(y_pred, index = y_real.index, columns = ['prediction'])], axis = 1).plot(kind = 'line', figsize = (20,6),\n",
        "                                                                                                           xlim=(y_real.index.min(),y_real.index.max()),\n",
        "                                                                                                           linewidth = 3, fontsize = 20)\n",
        "        plt.title('Time Series of Target', fontsize = 20)\n",
        "        plt.xlabel('Index', fontsize = 15)\n",
        "        plt.ylabel('Target Value', fontsize = 15)\n",
        "    MAE = abs(y_real.values.flatten() - y_pred).mean()\n",
        "    MSE = ((y_real.values.flatten() - y_pred)**2).mean()\n",
        "    MAPE = (abs(y_real.values.flatten() - y_pred)/y_real.values.flatten()*100).mean()\n",
        "    Score = pd.DataFrame([MAE, MSE, MAPE], index=['MAE', 'MSE', 'MAPE'], columns = ['Score']).T\n",
        "    Residual = pd.DataFrame(y_real.values.flatten() - y_pred, index = y_real.index, columns = ['Error'])\n",
        "    return Score, Residual"
      ],
      "metadata": {
        "id": "docF3fcdC0Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_trte(y_real_train, y_pred_train, y_real_test, y_pred_test, graph_on = False):\n",
        "    Score_tr, Residual_tr = evaluation(y_real_train, y_pred_train, graph_on = graph_on)\n",
        "    Score_te, Residual_te = evaluation(y_real_test, y_pred_test, graph_on = graph_on)\n",
        "    Score_trte = pd.concat([Score_tr, Score_te], axis=0)\n",
        "    Score_trte.index = ['Train', 'Test']\n",
        "    return Score_trte, Residual_tr, Residual_te"
      ],
      "metadata": {
        "id": "FaQnO-dfChJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_ols1 = sm.OLS(y_train1, X_train1).fit()\n",
        "display(fit_ols1.summary())"
      ],
      "metadata": {
        "id": "Hg6C073VvLuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_ols2 = sm.OLS(y_train1, X_train_sc1).fit()\n",
        "display(fit_ols2.summary()) "
      ],
      "metadata": {
        "id": "hkTRrM-EL9ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OLS 기법 기준모델 설정\n",
        "\n",
        "pred_train_ols1 = fit_ols1.predict(X_train1).values\n",
        "pred_test_ols1 = fit_ols1.predict(X_test1).values\n",
        "\n",
        "# 예측값 평가\n",
        "\n",
        "Score_reg1, Resid_train_reg1, Resid_test_reg1 = evaluation_trte(y_train1, pred_train_ols1, y_test1, pred_test_ols1, graph_on = True)\n",
        "print(Score_reg1)\n",
        "print(Resid_train_reg1)\n",
        "print(Resid_test_reg1)"
      ],
      "metadata": {
        "id": "M3ezXsDcCUPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일링된 자료를 통한 설정\n",
        "\n",
        "pred_train_ols2 = fit_ols2.predict(X_train_sc1).values\n",
        "pred_test_ols2 = fit_ols2.predict(X_test_sc1).values\n",
        "\n",
        "# 예측값 평가\n",
        "\n",
        "Score_reg2, Resid_train_reg2, Resid_test_reg2 = evaluation_trte(y_train1, pred_train_ols2, y_test1, pred_test_ols2, graph_on = True)\n",
        "print(Score_reg2)\n",
        "print(Resid_train_reg2)\n",
        "print(Resid_test_reg2)"
      ],
      "metadata": {
        "id": "CSPbpvoeMgaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = [0, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
        "\n",
        "# alpha list 값을 반복하면서 alpha 에 따른 평균 r제곱을 구함\n",
        "\n",
        "for alpha in alphas:\n",
        "\n",
        "\t# alpha 값들이 for문을 돌면서 새로운 ridge 회귀 객체를 생성\n",
        "\n",
        "    ridge = Ridge(alpha = alpha)\n",
        "    \n",
        "    # cross_val_score를 이용해 5 폴드의 평균 RMSE를 계산\n",
        "    \n",
        "    model1 = Ridge(alpha = alpha, fit_intercept = True, normalize = True, random_state = 2).fit(X_train1, y_train1)\n",
        "    model1.predict(X_train1)\n",
        "    y_pred1 = model1.predict(X_test1)\n",
        "    \n",
        "    # alpha 값의 가정에 따라 평균 5 folds의 R제곱이 어떻게 계산되는지 출력\n",
        "\n",
        "    print('alpha {0}일때 5 folds의 평균 Score: {1:.3f}'.format(alpha, model1.score(X_test1, y_test1)))"
      ],
      "metadata": {
        "id": "gw1KyZTG8oz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결국 alpha 값은 1일 때 가장 안정적인 모델이라고 보인다. 0.1 이하일 때는 과적합의 모습이 나타나고 10부터는 폐기 모델이 된다."
      ],
      "metadata": {
        "id": "7fp1bCSN9wY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Ridge(alpha = 1, fit_intercept = True, normalize = True, random_state = 2).fit(X_train1, y_train1)\n",
        "\n",
        "model1.predict(X_train1)\n",
        "y_pred1 = model1.predict(X_test1)\n",
        "\n",
        "print(f'훈련 모델 Score :{model1.score(X_train1, y_train1) : .3f}')\n",
        "print(f'Test 모델 Score :{model1.score(X_test1, y_test1) : .3f}')\n",
        "print(f'Test 모델 MSE :{mean_squared_error(y_test1, y_pred1) : .3f}')"
      ],
      "metadata": {
        "id": "zRfAXSy6t8zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.predict(X_train_sc1)\n",
        "y_sc_pred1 = model1.predict(X_test_sc1)\n",
        "\n",
        "print(f'훈련 모델 Score :{model1.score(X_train_sc1, y_train1) : .3f}')\n",
        "print(f'Test 모델 Score :{model1.score(X_test_sc1, y_test1) : .3f}')\n",
        "print(f'Test 모델 MSE :{mean_squared_error(y_test1, y_sc_pred1) : .3f}')"
      ],
      "metadata": {
        "id": "Dn9mEyAuj3Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "스케일링을 안한 데이터와 진행한 데이터를 비교한 결과 score에서 나타나듯 스케일링을 안한 데이터가 더 좋다고 보여진다."
      ],
      "metadata": {
        "id": "UaamTfG_kPgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross_Val_Score 로 교차검증 일반화 성능 검사\n",
        "\n",
        "cross_val_score(model1, X_train1, y_train1, scoring = None, cv = None)"
      ],
      "metadata": {
        "id": "B0M4d6QwJVUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = make_pipeline(\n",
        "    RandomForestRegressor(random_state = 2)\n",
        ")\n",
        "\n",
        "dists = {\n",
        "    'randomforestregressor__n_estimators': randint(10, 100, 500), \n",
        "    'randomforestregressor__max_depth': [5, 10, 20, 40, None], \n",
        "    'randomforestregressor__min_samples_leaf' : [8, 16, 32, None],\n",
        "    'randomforestregressor__min_samples_split' : [8, 16, 32, None]\n",
        "}\n",
        "\n",
        "clf = RandomizedSearchCV(\n",
        "    pipe, \n",
        "    param_distributions = dists, \n",
        "    n_iter = 10, \n",
        "    cv = 3, \n",
        "    scoring = 'neg_mean_absolute_error',  \n",
        "    verbose = 1,\n",
        "    n_jobs = -1\n",
        ")\n",
        "clf.fit(X_train1, y_train1);"
      ],
      "metadata": {
        "id": "RYbxi6fQacMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적 하이퍼파라미터: ', clf.best_params_)\n",
        "print('MAE: ', -clf.best_score_)"
      ],
      "metadata": {
        "id": "UKMfoRLQkr7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestRegressor(random_state = 2, max_depth = None, min_samples_leaf = 16, min_samples_split = 8, n_estimators = 549)\n",
        "\n",
        "model2.fit(X_train1, y_train1)\n",
        "y_pred2 = model2.predict(X_test1)\n",
        "\n",
        "print(f'훈련 모델 Score :{model2.score(X_train1, y_train1) : .3f}')\n",
        "print(f'Test 모델 Score :{model2.score(X_test1, y_test1) : .3f}')\n",
        "print(f'Test 모델 MSE :{mean_squared_error(y_test1, y_pred2) : .3f}')"
      ],
      "metadata": {
        "id": "5U3bbnGekyPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train_sc1, y_train1);"
      ],
      "metadata": {
        "id": "xO908w-fkdEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적 하이퍼파라미터: ', clf.best_params_)\n",
        "print('MAE: ', -clf.best_score_)"
      ],
      "metadata": {
        "id": "tJiftQarkwTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestRegressor(random_state = 2, max_depth = 10, min_samples_leaf = 16, min_samples_split = 8, n_estimators = 594)\n",
        "\n",
        "model2.fit(X_train_sc1, y_train1)\n",
        "y_sc_pred2 = model2.predict(X_test_sc1)\n",
        "\n",
        "print(f'훈련 모델 Score :{model2.score(X_train_sc1, y_train1) : .3f}')\n",
        "print(f'Test 모델 Score :{model2.score(X_test_sc1, y_test1) : .3f}')\n",
        "print(f'Test 모델 MSE :{mean_squared_error(y_test1, y_sc_pred2) : .3f}')"
      ],
      "metadata": {
        "id": "fkxsAU8zkzKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe1 = make_pipeline(\n",
        "    LGBMRegressor(random_state = 2)\n",
        ")\n",
        "\n",
        "dists1 = {\n",
        "    'lgbmregressor__n_estimators': randint(10, 100, 500), \n",
        "    'lgbmregressor__learning_rate': [0.05, 0.1, 0.2, 0.40]\n",
        "}\n",
        "\n",
        "clf1 = RandomizedSearchCV(\n",
        "    pipe1, \n",
        "    param_distributions = dists1, \n",
        "    n_iter = 10, \n",
        "    cv = 3, \n",
        "    scoring = 'neg_mean_absolute_error',  \n",
        "    verbose = 1,\n",
        "    n_jobs = -1\n",
        ")\n",
        "clf1.fit(X_train1, y_train1);"
      ],
      "metadata": {
        "id": "ZITUZLbvMhmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('최적 하이퍼파라미터: ', clf1.best_params_)\n",
        "print('MAE: ', -clf1.best_score_)"
      ],
      "metadata": {
        "id": "Z-7fi3G4Qf_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = LGBMRegressor(learning_rate = 0.05, n_estimators = 550, random_state = 2).fit(X_train1, y_train1)\n",
        "\n",
        "model3.predict(X_train1)\n",
        "y_pred3 = model3.predict(X_test1)\n",
        "\n",
        "print(f'훈련 모델 Score :{model3.score(X_train1, y_train1) : .3f}')\n",
        "print(f'Test 모델 Score :{model3.score(X_test1, y_test1) : .3f}')\n",
        "print(f'Test 모델 MSE :{mean_squared_error(y_test1, y_pred3) : .3f}')"
      ],
      "metadata": {
        "id": "qMeatJaF7sEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 별 평가 결과\n",
        "\n",
        "1. model1(Ridge회귀 사용)은 1에 가까운 평가 지표가 나왔다. 이는 아마 과적합이 의심된다. alpha 값을 조정해서 수치를 변경해준다.\n",
        "\n",
        "2. model2(RandomForestRegressor)와 model3(LGBMRegressor)의 경우 test셋에서 음수의 r제곱 값의 평가 지표가 나왔다. 폐기를 해야할 정도로 안좋은 모델이라고 생각한다.\n",
        "\n",
        "3. 다른 target으로 잡은 Low 도 같은 방법으로 사용할 수 있다."
      ],
      "metadata": {
        "id": "nuGrmj_jXQb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple_tomorrow = pd.DataFrame({'Open' : [143], 'Close' : [146], 'Adj' : [146] , 'Vol' : [109742900], 'NA_12' : [150], 'NA_26' : [158], 'RSI' : [45] , 'BOL_H' : [170], 'BOL_L' : [142], 'MACD' : [-5.21], 'SIGNAL' : [-3.03]})\n",
        "\n",
        "apple_tomorrow"
      ],
      "metadata": {
        "id": "NBp6HMXioUcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Ridge(alpha = 1, fit_intercept = True, normalize = True, random_state = 2).fit(X_train1, y_train1)\n",
        "\n",
        "X_train1.columns"
      ],
      "metadata": {
        "id": "xu8PmOy4veXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.displot(y_train1, kde = True);"
      ],
      "metadata": {
        "id": "UQyxKRmewDGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('R^2', model1.score(X_test1, y_test1))"
      ],
      "metadata": {
        "id": "CrdV2Atjwj49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isolated = pdp_isolate(\n",
        "    model = model1, \n",
        "    dataset = X_test1, \n",
        "    model_features = X_test1.columns, \n",
        "    feature = 'Open',\n",
        "    grid_type = 'percentile',\n",
        "    num_grid_points = 10\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name = 'Open', plot_lines = True)"
      ],
      "metadata": {
        "id": "Vcy0NJD0wNRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isolated = pdp_isolate(\n",
        "    model = model1, \n",
        "    dataset = X_test1, \n",
        "    model_features = X_test1.columns, \n",
        "    feature = 'Vol',\n",
        "    grid_type = 'percentile',\n",
        "    num_grid_points = 10\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name = 'Vol', plot_lines = True)"
      ],
      "metadata": {
        "id": "mTIe5X5exUdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isolated = pdp_isolate(\n",
        "    model = model1, \n",
        "    dataset = X_test1, \n",
        "    model_features = X_test1.columns, \n",
        "    feature = 'RSI',\n",
        "    grid_type = 'percentile',\n",
        "    num_grid_points = 10\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name = 'RSI', plot_lines = True)"
      ],
      "metadata": {
        "id": "5SxuhhP0xPMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isolated = pdp_isolate(\n",
        "    model = model1, \n",
        "    dataset = X_test1, \n",
        "    model_features = X_test1.columns, \n",
        "    feature = 'MACD',\n",
        "    grid_type = 'percentile',\n",
        "    num_grid_points = 10\n",
        ")\n",
        "\n",
        "pdp_plot(isolated, feature_name = 'MACD', plot_lines = True)"
      ],
      "metadata": {
        "id": "KLWg6YxxxmB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDP를 사용해보자\n",
        "\n",
        "1. 일단 연관성이 그렇게 짙게 나오지 않는 column 들을 가지고 PDP분석을 해보자\n",
        "\n",
        "2. 시초가, RSI, MACD의 경우는 양의 선형관계로 타겟 변수에 같은 방향의 영향을 미친다고 나타난다.\n",
        "\n",
        "3. 거래량의 경우는 음의 선형관계로 타겟 변수와 반대 방향을 주는 영향성을 나타낸다고 알 수 있다."
      ],
      "metadata": {
        "id": "WmHmGIMJxxCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Ridge(alpha = 0.5, fit_intercept = True, normalize = True, random_state = 2).fit(X_train1, y_train1)\n",
        "\n",
        "model4.predict(X_train1)\n",
        "y_pred4 = model4.predict(X_test1)\n",
        "\n",
        "print(f'훈련 모델 Score :{model4.score(X_train1, y_train1) : .3f}')\n",
        "print(f'Test 모델 Score :{model4.score(X_test1, y_test1) : .3f}')\n",
        "print(f'Test 모델 MSE :{mean_squared_error(y_test1, y_pred4) : .3f}')"
      ],
      "metadata": {
        "id": "6WTzLePUqSRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tomo = model4.predict(apple_tomorrow)\n",
        "\n",
        "tomo"
      ],
      "metadata": {
        "id": "SMbuoMu9oahQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 오차 범위가 크게 나오기 때문에 이정도의 예측치라면 나쁘지는 않을지 모른다\n",
        "\n",
        "2. RMSE 값이 약 8 정도 나온다.\n",
        "\n",
        "3. 최고 값을 구해야 하기 때문에 나온 값과 RMSE 값을 더해 줘 보자\n",
        "\n",
        "4. 144~145 정도의 값이 나온다.\n",
        "\n",
        "5. 오늘 시작하는 장에서 136 ~ 145 사이의 값이 나올 것이라고 예측이 가능하다."
      ],
      "metadata": {
        "id": "M_l2Lan42VDZ"
      }
    }
  ]
}